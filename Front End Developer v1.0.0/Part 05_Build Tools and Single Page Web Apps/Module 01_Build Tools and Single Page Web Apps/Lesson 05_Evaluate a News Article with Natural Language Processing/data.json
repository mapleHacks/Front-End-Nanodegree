{
  "data": {
    "lesson": {
      "id": 906473,
      "key": "adbf2a15-5fa5-466b-a8fe-19ce08b82b61",
      "title": "Evaluate a News Article with Natural Language Processing",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Build a web tool that allows users to run Natural Language Processing (NLP) on articles or blogs found on other websites.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": false,
      "resources": null,
      "project": {
        "key": "391dad87-db77-43f8-a84d-348ec20f259e",
        "version": "1.0.0",
        "locale": "en-us",
        "duration": 30240,
        "semantic_type": "Project",
        "title": "Evaluate a News Article with Natural Language Processing",
        "description": "# Evaluate a News Article with Natural Language Processing\n\nThis project requires you to build a web tool that allows users to run Natural Language Processing (NLP) on articles or blogs found on other websites.\n\n## Rubric\n\nYour project will be evaluated by a Udacity code reviewer according to the [project rubric](https://review.udacity.com/#!/rubrics/2668/view). Please make sure to re-review the rubric for detailed project requirements prior to submission.\n\n## Submission\n\nOnce you've met all of the rubric requirements, you can submit your project as either a zip file or a Github repository link.",
        "is_public": true,
        "summary": null,
        "forum_path": "",
        "rubric_id": "2668",
        "terminal_project_id": null,
        "resources": null,
        "image": null
      },
      "lab": null,
      "concepts": [
        {
          "id": 906475,
          "key": "84dd3e36-517c-4683-8d46-78384355b372",
          "title": "Introduction",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "84dd3e36-517c-4683-8d46-78384355b372",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 906476,
              "key": "0475ea69-1e14-4da3-9c30-9038d4a8c6ea",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Project Summary\n\nThe goal of this project is to give you a taste of the environment and tools you will most likely come across in a front end role. Your focus should be to understand the role every tool and technology is playing in the overall architecture, but you shouldn’t feel the need to memorize the particular commands, config setups, or structure that we create here. Every company - and even every project - will have its own custom setup, but if you understand the moving pieces you will be able to get the gist of even far more complicated projects than this one. \n\n### What You Will Build\n\nWe will be building web tool that allows users to run Natural Language Processing (NLP) on articles or blogs found on other websites. Using an exciting new api called [Aylien](https://aylien.com/), we can build a simple web interface to interact with their NLP system. This tool will give us back pertinent information about the article, like whether the content is subjective (opinion) or objective (fact-based) and whether it is positive, neutral, or negative in tone. \n\nNode and express will be the webserver and routing, and webpack will be our build tool of choice. Using webpack, we will set up the app to have dev and prod environments, each with their own set of tools and commands. \n\n### More About Natural Language Processing\n\nNLP is considered its own branch of computer science, focused on computers’ ability to process and even interact with natural human speech. Machine learning and deep learning are used on massive amounts of data to obtain the rules and understanding of nuance in human speech. Everyone who has used Alexa or Google Assistant or other voice command systems knows that they are always improving - but they aren’t perfect. Verbal interactions can be incredibly hard to decipher. Sarcasm, for instance, requires understanding not just words and grammar but tone as well, and regional accents and ways of saying things have to be taken into account, not to mention coverage for all the major languages. ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 925478,
          "key": "5675966c-1a35-4d58-8715-e279d2303167",
          "title": "Instructions",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "5675966c-1a35-4d58-8715-e279d2303167",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 925479,
              "key": "376e00d0-5a2e-4200-a4d1-8625187163ba",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Project Instructions\n[This repo](https://github.com/udacity/fend/tree/refresh-2019) is your starter code for the project (clone the specific branch 'refresh-2019' or download the ZIP file), although feel free to start from scratch! It is the same as the starter code we began with in lesson 2. Install and configure Webpack just as we did in the course. Feel free to refer to the course repo as you build this one, and remember to make frequent commits and to create and merge branches as necessary!\n\nThe goal of this project is to give you practice with:\n- Setting up Webpack\n- Sass styles\n- Webpack Loaders and Plugins\n- Creating layouts and page design\n- Service workers\n- Using APIs and creating requests to external urls\n\nOn top of that, I want to introduce you to the topic of Natural Language Processing. NLPs leverage machine learning and deep learning create a program that can interpret natural human speech. Systems like Alexa, Google Assistant, and many voice interaction programs are well known to us, but understanding human speech is an incredibly difficult task and requires a lot of resources to achieve. Full disclosure, this is the Wikipedia definition, but I found it to be a clear one:\n\n> Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence\nconcerned with the interactions between computers and human (natural) languages, in particular how to program computers to\nprocess and analyze large amounts of natural language data.\n\nYou could spend years and get a masters degree focusing on the details of creating NLP systems and algorithms. Typically, NLP programs require far more resources than individuals have access to, but a fairly new API called Aylien has put a public facing API in front of their NLP system. We will use it in this project to determine various attributes of an article or blog post.",
              "instructor_notes": ""
            },
            {
              "id": 925480,
              "key": "a7e81ac6-37aa-4baa-af32-db6bbb93b1d9",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Getting started\n\nIt would probably be good to first get your basic project setup and functioning. Follow the steps from the course up to Lesson 4 but don't add Service Workers just yet. We won't need the service workers during development and having extra caches floating around just means there's more potential for confusion. So, fork this repo and begin your project setup.\n\nRemember that once you clone, you will still need to install everything:\n\n`cd` into your new folder and run:\n- `npm install`",
              "instructor_notes": ""
            },
            {
              "id": 925481,
              "key": "8be5467f-d03b-4252-bb6a-2244bdcd0166",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Setting up the API\n\nThe Aylien API is perhaps different than what you've used before. It has you install a node module to run certain commands through, it will simplify the requests we need to make from our node/express backend.\n\n### Step 1: Signup for an API key\nFirst, you will need to go [here](https://developer.aylien.com/signup). Signing up will get you an API key. Don't worry, at the time of this course, the API is free to use up to 1000 requests per day or 333 intensive requests. It is free to check how many requests you have remaining for the day.\n\n### Step 2: Install the SDK\nNext you'll need to get the SDK. SDK stands for Software Development Kit, and SDKs are usually a program that brings together various tools to help you work with a specific technology. SDKs will be available for all the major languages and platforms, for instance the Aylien SDK brings together a bunch of tools and functions that will make it possible to interface with their API from our server and is available for Node, Python, PHP, Go, Ruby and many others. We are going to use the Node one, the page is available [here](https://docs.aylien.com/textapi/sdks/#sdks). You get 1000 free requests per day. \n\n### Step 3: Require the SDK package\nInstall the SDK in your project and then we'll be ready to set up your server/index.js file.\n\nYour server index.js file must have these things:\n\n- [ ] Require the Aylien npm package\n```\nvar aylien = require(\"aylien_textapi\");\n```\n\n### Step 4: Environment Variables\nNext we need to declare our API keys, which will look something like this:\n```\n// set aylien API credentias\nvar textapi = new aylien({\n  application_id: \"your-api-id\",\n  application_key: \"your-key\"\n});\n```\n\n...but there's a problem with this. We are about to put our personal API keys into a file, but when we push, this file is going to be available PUBLICLY on Github. Private keys, visible publicly are never a good thing. So, we have to figure out a way to make that not happen. The way we will do that is with environment variables. Environment variables are pretty much like normal variables in that they have a name and hold a value, but these variables only belong to your system and won't be visible when you push to a different environment like Github.\n\n- [ ] Use npm or yarn to install the dotenv package ```npm install dotenv```. This will allow us to use environment variables we set in a new file\n- [ ] Create a new ```.env``` file in the root of your project\n- [ ] Go to your .gitignore file and add ```.env``` - this will make sure that we don't push our environment variables to Github! If you forget this step, all of the work we did to protect our API keys was pointless.\n- [ ] Fill the .env file with your API keys like this:\n```\nAPI_ID=**************************\nAPI_KEY=**************************\n```\n- [ ] Add this code to the very top of your server/index.js file:\n```\nconst dotenv = require('dotenv');\ndotenv.config();\n```\n- [ ] Reference variables you created in the .env file by putting ```process.env``` in front of it, an example might look like this:\n```\nconsole.log(`Your API key is ${process.env.API_KEY}`);\n```\n...Not that you would want to do that. This means that our updated API credential settings will look like this:\n```javascript\n// set aylien API credentials\n// NOTICE that textapi is the name I used, but it is arbitrary.\n// You could call it aylienapi, nlp, or anything else, \n//   just make sure to make that change universally!\nvar textapi = new aylien({\n  application_id: process.env.API_ID,\n  application_key: process.env.API_KEY\n});\n```\n\n### Step 5: Using the API\n\nWe're ready to go! The API has a lot of different endpoints you can take a look at [here](https://docs.aylien.com/textapi/endpoints/#api-endpoints). And you can see how using the SDK simplifies the requests we need to make. \n\nI won't provide further examples here, as it's up to you to create the various requests and make sure your server is set up appropriately.",
              "instructor_notes": ""
            },
            {
              "id": 925486,
              "key": "6c40c57f-01d6-4261-9c22-9316c1ce5459",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## After the Aylien API\n\nOnce you are hooked up to the Aylien API, you are most of the way there! Along with making sure you are following all the requirements in the [project rubric](https://review.udacity.com/#!/rubrics/2668/view), here are a few other steps to make sure you take.\n\n- Parse the response body to dynamically fill content on the page.  \n\n- Test that the server and form submission work, making sure to also handle error responses if the user input does not match API requirements.  You should add [Jest](https://jestjs.io/en/) to your project to handle testing as well.\n\n- Go back to the web pack config and add the setup for service workers.  \n\n- Test that the site is now available even when you stop your local server \n\nNeed a refresher on writing unit tests? Check out these resources:\n- [Jest Documentation](https://jestjs.io/docs/en/getting-started)\n- [Jest Tutorial for Beginners](https://www.valentinog.com/blog/jest/)",
              "instructor_notes": ""
            },
            {
              "id": 925482,
              "key": "7a6340fe-7e1e-40c7-af8c-f26c8cde4fff",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "## Deploying\n\nA great step to take with your finished project would be to deploy it! Unfortunately its a bit out of scope for me to explain too much about how to do that here, but checkout [Netlify](https://www.netlify.com/) or [Heroku](https://www.heroku.com/) for some really intuitive free hosting options.",
              "instructor_notes": ""
            }
          ]
        }
      ]
    }
  }
}